{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8f4724-ac80-4a3a-a8c7-e21d3664acdc",
   "metadata": {},
   "source": [
    "### Data Ingestion from video (Youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d6c6db-c914-49bb-8af6-7b7d9caf11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import youtube_transcript_api\n",
    "from datetime import timedelta\n",
    "import srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd1108-528a-417f-9930-80cac4ad47e5",
   "metadata": {},
   "source": [
    "#https://www.youtube.com/watch?v=Mot91oWrDX0\n",
    "- one sample video for data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69efd341-9138-43cd-b847-73bcefd0333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = {\n",
    "    \"id\": [\"Mot91oWrDX0\"],\n",
    "    \"title\": [\"BUILD23 - Gary Brecka\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361e8922-8572-4ded-b6e2-6552232a27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first expectation test\n",
    "assert len(videos[\"title\"]) == len(videos[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6528cff1-136a-4237-9d5e-c985852ac308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mot91oWrDX0</th>\n",
       "      <td>BUILD23 - Gary Brecka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title\n",
       "id                                \n",
       "Mot91oWrDX0  BUILD23 - Gary Brecka"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df = pd.DataFrame.from_dict(videos)\n",
    "videos_df.index = videos_df[\"id\"]\n",
    "videos_df = videos_df.drop(\"id\", axis=\"columns\")\n",
    "videos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e85be5-6d6d-4fd6-904e-10858fca1a81",
   "metadata": {},
   "source": [
    "We use the youtube_transcript_api package to pull down the transcripts in a single line of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e485f3-4c58-46ab-9192-e0dc2a772c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71.8 ms, sys: 11.7 ms, total: 83.5 ms\n",
      "Wall time: 942 ms\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "\n",
    "%time transcripts = [YouTubeTranscriptApi.get_transcript(video_id) for video_id in videos_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfdc91a-1ef7-414b-bdda-817a1c4d0bfa",
   "metadata": {},
   "source": [
    "Conveniently enough, every second of a YouTube video is individually linkable and the transcripts come with timestamps.\n",
    "\n",
    "But a second of speech is not a useful source.\n",
    "\n",
    "And by default, the subtitles come \"chunked\" in time at too fine a grain as well: more like five seconds than the thirty to sixty seconds that it takes to make a reasonable point.\n",
    "\n",
    "So now, we combine the five-second subtitle timestamps into longer chunks based on character count -- 750 seems to generate nicely sized chunks on our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e49c429-d32e-474f-b43b-00309655153e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'this speaker', 'start': 0.12, 'duration': 4.32},\n",
       " {'text': 'outperformed Tony Robbins last year he',\n",
       "  'start': 1.7,\n",
       "  'duration': 4.78},\n",
       " {'text': 'was more popular and people love Tony',\n",
       "  'start': 4.44,\n",
       "  'duration': 4.44},\n",
       " {'text': \"Robbins it's no put in not sailing\",\n",
       "  'start': 6.48,\n",
       "  'duration': 4.26},\n",
       " {'text': \"against Tony he's amazing I love the guy\",\n",
       "  'start': 8.88,\n",
       "  'duration': 4.5}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54f50168-0dde-4f94-b61e-3d9d87c72bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 ms, sys: 20 µs, total: 2.28 ms\n",
      "Wall time: 2.3 ms\n",
      "CPU times: user 1.48 ms, sys: 87 µs, total: 1.56 ms\n",
      "Wall time: 1.66 ms\n"
     ]
    }
   ],
   "source": [
    "TRIGGER_LENGTH = 750  # 30-60 seconds\n",
    "\n",
    "def merge(subtitles, idx):\n",
    "    new_content = combine_content(subtitles)\n",
    "\n",
    "    # preserve start as timedelta\n",
    "    new_start = seconds_float_to_timedelta(subtitles[0][\"start\"])\n",
    "    # merge durations as timedelta\n",
    "    new_duration = seconds_float_to_timedelta(sum(sub[\"duration\"] for sub in subtitles))\n",
    "\n",
    "    # combine\n",
    "    new_end = new_start + new_duration\n",
    "\n",
    "    return srt.Subtitle(index=idx, start=new_start, end=new_end, content=new_content)\n",
    "\n",
    "\n",
    "def combine_content(subtitles):\n",
    "    contents = [subtitle[\"text\"].strip() for subtitle in subtitles]\n",
    "    return \" \".join(contents) + \"\\n\\n\"\n",
    "\n",
    "\n",
    "def get_charcount(subtitle):\n",
    "    return len(subtitle[\"text\"])\n",
    "\n",
    "\n",
    "def seconds_float_to_timedelta(x_seconds):\n",
    "    return timedelta(seconds=x_seconds)\n",
    "\n",
    "\n",
    "def merge_subtitles(subtitles):\n",
    "    merged_subtitles = []\n",
    "    current_chunk, current_length, chunk_idx = [], 0, 1\n",
    "\n",
    "    for subtitle in subtitles:\n",
    "        current_chunk.append(subtitle)\n",
    "        added_length = get_charcount(subtitle)\n",
    "        new_length = current_length + added_length\n",
    "\n",
    "        if new_length >= TRIGGER_LENGTH:\n",
    "            merged_subtitle = merge(current_chunk, chunk_idx)\n",
    "            merged_subtitles.append(merged_subtitle)\n",
    "            current_chunk, current_length = [], 0\n",
    "            chunk_idx += 1\n",
    "        else:\n",
    "            current_length = new_length\n",
    "\n",
    "    if current_chunk:\n",
    "        merged_subtitle = merge(current_chunk, chunk_idx)\n",
    "        merged_subtitles.append(merged_subtitle)\n",
    "\n",
    "    return merged_subtitles\n",
    "\n",
    "\n",
    "%time subtitle_collections = [merge_subtitles(transcript) for transcript in transcripts]\n",
    "\n",
    "# get strings as well for quick checks (and easier to write to files)\n",
    "%time subtitle_strings = [srt.compose(merged_subtitles) for merged_subtitles in subtitle_collections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be2a3975-5df3-4a2d-a159-7fbb43b6c948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Subtitle(index=1, start=datetime.timedelta(microseconds=120000), end=datetime.timedelta(seconds=102, microseconds=119000), content=\"this speaker outperformed Tony Robbins last year he was more popular and people love Tony Robbins it's no put in not sailing against Tony he's amazing I love the guy but people said he was better so let me ask you a question imagine you're living in your dream home you got the cabin for the family the beach house your bills are paid you've built something big but you don't have your health I remember Curtis crawling through his house for months literally sliding on a piece of cardboard his wife would drag him through the house because he couldn't walk how important is our health well our final speaker today is about to rock your world about elite health not just yeah I'm healthy I mean Elite levels of health help me welcome the stage one of my favorite well no no no no no no no\\n\\n\", proprietary=''),\n",
       " Subtitle(index=2, start=datetime.timedelta(seconds=50, microseconds=39000), end=datetime.timedelta(seconds=158, microseconds=159000), content=\"roll the video here we go you're one of my best friends you've been such a good friend of me blah blah there's nothing I could ever do for you so I'm going to do this I'm going to introduce you to this guy named Gary brecka [Music] I know Gary brecka our friend yeah Gary I love Gary by the way I love Gary yeah my name is Gary breckov I'm a human biologist researcher and a biohacker for 20 years I spent my lifetime working in the insurance industry predicting mortality to the month which meant if I got five years of medical records and five years of demographic data the team that I was associated with could actually tell an insurance company how long you had to live to the month after years and years of this type of research and Analysis I realized one thing there were human beings on the other\\n\\n\", proprietary='')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle_collections[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaad9230-b9d0-4104-bb7c-4a9fa84d1c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\\n00:00:00,120 --> 00:01:42,119\\nthis speaker outperformed Tony Robbins last year he was more popular and people love Tony Robbins it's no put in not sailing against Tony he's amazing I love the guy but people said he was better so let me ask you a question imagine you're living in your dream home you got the cabin for the family the beach house your bills are paid you've built something big but you don't have your health I remember Curtis crawling through his house for months literally sliding on a piece of cardboard his wife would drag him through the house because he couldn't walk how important is our health well our final speaker today is about to rock your world about elite health not just yeah I'm healthy I mean Elite levels of health \""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle_strings[0][:750]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b3ecf-0783-4015-9ca5-0e0eb6cfb6e4",
   "metadata": {},
   "source": [
    "We then add YouTube URLs for those longer subtitles as sources and combine them into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e511ec-8fd0-4d4f-919a-eb94413861c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_format = \"https://www.youtube.com/watch?v={id}\"\n",
    "query_params_format = \"&t={start}s\"\n",
    "\n",
    "\n",
    "def create_split_video_df(subtitles, base_url):\n",
    "    rows = []\n",
    "    for subtitle in subtitles:\n",
    "        raw_text = subtitle.content\n",
    "        text = raw_text.strip()\n",
    "        start = timestamp_from_timedelta(subtitle.start)\n",
    "        url = base_url + query_params_format.format(start=start)\n",
    "\n",
    "        rows.append({\"text\": text, \"source\": url})\n",
    "\n",
    "    video_df = pd.DataFrame.from_records(rows)\n",
    "    return video_df\n",
    "\n",
    "\n",
    "def timestamp_from_timedelta(td):\n",
    "    return int(td.total_seconds())\n",
    "\n",
    "\n",
    "split_video_dfs = [\n",
    "    create_split_video_df(subtitles, base_url_format.format(id=video_id))\n",
    "    for subtitles, video_id in zip(subtitle_collections, videos_df.index)\n",
    "]\n",
    "\n",
    "%time split_video_df = pd.concat(split_video_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992a4bf-d31b-4831-b338-049e538febcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time split_video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0beead-2e1c-489d-a53f-f2a762e2ff59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
